{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fd71eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x14e4b3f55b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import sys; sys.argv=['']; del sys\n",
    "import time\n",
    "\n",
    "\n",
    "seed=200\n",
    "np.random.random(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60b888e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HH_Dataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self,root_dir,X,Y,train=True):\n",
    "\n",
    "        self.data=(X.values.astype(np.float32),Y.values.astype(int))\n",
    "        self.train=train\n",
    "        self.root_dir=root_dir\n",
    "        self.train=train\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data[1])\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        sample=(self.data[0][idx,...],self.data[1][idx])\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00c92ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset_size=None):\n",
    "    data_file='datacsv3.csv'\n",
    "    root_dir=''\n",
    "    \n",
    "    features=['x-position','x-momentum','y-position','y-momentum','Energy','Periodic']\n",
    "    df=pd.read_csv(root_dir+data_file,header=None,nrows=dataset_size,engine='python')\n",
    "    df.columns=features\n",
    "    df.sample(frac=1)\n",
    "    \n",
    "    X=df[['x-position','x-momentum','y-position','y-momentum','Energy']]\n",
    "    Y=df['Periodic']\n",
    "    \n",
    "    #Y=df['Energy']\n",
    "    #X=df[['x-position','x-momentum','y-position','y-momentum']]\n",
    "    \n",
    "    dataset_size=X.shape[0]\n",
    "            \n",
    "    train_size=int(0.8*dataset_size)\n",
    "    train_X=X[:train_size]\n",
    "    train_Y=Y[:train_size]\n",
    "    test_X=X[train_size:]\n",
    "    test_Y=Y[train_size:]\n",
    "    \n",
    "    batch_size=int(0.01*dataset_size)\n",
    "    \n",
    "    test_loader=torch.utils.data.DataLoader(HH_Dataset(root_dir,test_X,test_Y,train=False),batch_size=1000,shuffle=True)\n",
    "    train_loader=torch.utils.data.DataLoader(HH_Dataset(root_dir,train_X,train_Y),batch_size=batch_size,shuffle=True)\n",
    "    \n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8a1b843",
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(nn.Module):\n",
    "    def __init__(self,neurons):\n",
    "        super(model,self).__init__()\n",
    "        \n",
    "        self.mid_neurons=neurons\n",
    "        \n",
    "        self.fc1=nn.Linear(5,self.mid_neurons)\n",
    "        #self.fc1=nn.Linear(4,self.mid_neurons)\n",
    "        self.fc2=nn.Linear(self.mid_neurons,200)\n",
    "        self.fc3=nn.Linear(200,2)\n",
    "        \n",
    "        #self.fc3=nn.Linear(200,100)\n",
    "        #self.fc4=nn.Linear(100,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=F.dropout(x,training=self.training)\n",
    "        x=F.relu(self.fc2(x))\n",
    "        x=F.dropout(x,training=self.training)\n",
    "        x=self.fc3(x)\n",
    "        x=F.log_softmax(x,dim=1)\n",
    "        \n",
    "        #x=F.relu(x)\n",
    "        #x=self.fc4(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1843399",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(args, train_loader, test_loader):\n",
    "    DNN=model(args.neurons)\n",
    "    criterion=F.nll_loss\n",
    "    optimizer=args.optimizer(DNN.parameters(),lr=args.lr,weight_decay=args.l2)\n",
    "\n",
    "    \n",
    "    def train(epoch):\n",
    "        DNN.train()\n",
    "        for batch_idx, (data,label) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            output=DNN(data)\n",
    "            \n",
    "            label=label.type(torch.LongTensor)\n",
    "            loss=criterion(output,label)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if batch_idx%10==0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader), loss.item() ))\n",
    "                \n",
    "        return loss.item()\n",
    "    \n",
    "    def test():\n",
    "        DNN.eval()\n",
    "        test_loss=0\n",
    "        correct=0\n",
    "        \n",
    "        for data,label in test_loader:\n",
    "            output=DNN(data)\n",
    "            label=label.type(torch.LongTensor)\n",
    "            test_loss+=criterion(output,label).item()\n",
    "            pred=output.data.max(1,keepdim=True)[1]\n",
    "            correct+=pred.eq(label.data.view_as(pred)).cpu().sum().item()\n",
    "        \n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        \n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.3f}%)\\n'.format(\n",
    "            test_loss, correct, len(test_loader.dataset),\n",
    "            100. * correct / len(test_loader.dataset)))\n",
    "        \n",
    "\n",
    "        return test_loss, correct / len(test_loader.dataset)\n",
    "        \n",
    "    \n",
    "    train_loss=np.zeros((10,))\n",
    "    test_loss=np.zeros_like(train_loss)\n",
    "    test_accuracy=np.zeros_like(test_loss)\n",
    "    \n",
    "    epochs=range(1,11)\n",
    "    for epoch in epochs:\n",
    "        train_loss[epoch-1]=train(epoch)\n",
    "        test_loss[epoch-1],test_accuracy[epoch-1]=test()\n",
    "            \n",
    "    return test_loss[-1],test_accuracy[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b8e529c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(args):\n",
    "    middle_neurons=[50,100,200,400]\n",
    "    optimizers=[optim.SGD,optim.Adam,optim.RMSprop,optim.Adagrad]\n",
    "    optimizer_name=['SGD','ADAM','RMSPROP','ADAGRAD']\n",
    "    lr=[10**(-3),10**(-4),10**(-2),10**(-2)]\n",
    "    l2_regularizer=np.logspace(-4,0,5)\n",
    "    \n",
    "    test_loss=np.zeros((len(middle_neurons),len(optimizers),l2_regularizer.shape[0]))\n",
    "    test_accuracy=np.zeros_like(test_loss)\n",
    "    \n",
    "    train_loader,test_loader=load_data(1200000)\n",
    "    \n",
    "    for i,optimizer in enumerate(optimizers):\n",
    "        args.optimizer=optimizer\n",
    "        for j,neurons in enumerate(middle_neurons):\n",
    "            args.neurons=neurons\n",
    "            for k,l2 in enumerate(l2_regularizer):\n",
    "                args.l2=l2\n",
    "                print(\"\\n training DNN with %d neurons and \"%(neurons)+optimizer_name[i]+\" with l2 regularizer = %0.6f\"%(l2))\n",
    "                test_loss[i,j,k],test_accuracy[i,j,k]=evaluate_model(args,train_loader,test_loader)\n",
    "                \n",
    "        plot_data(l2_regularizer,middle_neurons,test_accuracy[i,:,:],optimizer_name[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f97e79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(x,y,data,name):\n",
    "        # plot results\n",
    "    fontsize=16\n",
    "\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(data, interpolation='nearest', vmin=0, vmax=1)\n",
    "    \n",
    "    cbar=fig.colorbar(cax)\n",
    "    cbar.ax.set_ylabel('accuracy (%)',rotation=90,fontsize=fontsize)\n",
    "    cbar.set_ticks([0,.2,.4,0.6,0.8,1.0])\n",
    "    cbar.set_ticklabels(['0%','20%','40%','60%','80%','100%'])\n",
    "\n",
    "    # put text on matrix elements\n",
    "    for i, x_val in enumerate(np.arange(len(x))):\n",
    "        for j, y_val in enumerate(np.arange(len(y))):\n",
    "            c = \"${0:.1f}\\\\%$\".format( 100*data[j,i])  \n",
    "            ax.text(x_val, y_val, c, va='center', ha='center')\n",
    "\n",
    "    # convert axis vaues to to string labels\n",
    "    x=[str(i) for i in x]\n",
    "    y=[str(i) for i in y]\n",
    "\n",
    "\n",
    "    ax.set_xticklabels(['']+x)\n",
    "    ax.set_yticklabels(['']+y)\n",
    "\n",
    "    ax.set_xlabel('$\\\\mathrm{l2\\\\ regularizer}$',fontsize=fontsize)\n",
    "    ax.set_ylabel('$\\\\mathrm{number\\\\ of\\\\ neurons\\\\ middle\\\\ layer}$',fontsize=fontsize)\n",
    "    ax.set_title(name)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig.savefig('HH_dataset_'+name+'.png')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0f9640b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser=argparse.ArgumentParser(description='HenonHeiles DNN')\n",
    "parser.add_argument('--neurons',type=int,default=200,metavar='MN')\n",
    "parser.add_argument('--optimizer',type=object,default=optim.SGD,metavar='OPT')\n",
    "parser.add_argument('--l2',type=float,default=10**(-3),metavar='L2')\n",
    "parser.add_argument('--lr',type=float,default=10**(-3),metavar='LR')\n",
    "args=parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f673db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " training DNN with 50 neurons and SGD with l2 regularizer = 0.000100\n",
      "Train Epoch: 1 [0/960000 (0%)]\tLoss: 0.723865\n",
      "Train Epoch: 1 [120000/960000 (12%)]\tLoss: 0.706938\n",
      "Train Epoch: 1 [240000/960000 (25%)]\tLoss: 0.689732\n",
      "Train Epoch: 1 [360000/960000 (38%)]\tLoss: 0.673882\n",
      "Train Epoch: 1 [480000/960000 (50%)]\tLoss: 0.658310\n",
      "Train Epoch: 1 [600000/960000 (62%)]\tLoss: 0.642472\n",
      "Train Epoch: 1 [720000/960000 (75%)]\tLoss: 0.629162\n",
      "Train Epoch: 1 [840000/960000 (88%)]\tLoss: 0.614160\n",
      "\n",
      "Test set: Average loss: 0.0006, Accuracy: 240000/240000 (100.000%)\n",
      "\n",
      "Train Epoch: 2 [0/960000 (0%)]\tLoss: 0.600413\n",
      "Train Epoch: 2 [120000/960000 (12%)]\tLoss: 0.586570\n",
      "Train Epoch: 2 [240000/960000 (25%)]\tLoss: 0.573299\n",
      "Train Epoch: 2 [360000/960000 (38%)]\tLoss: 0.560743\n",
      "Train Epoch: 2 [480000/960000 (50%)]\tLoss: 0.549457\n",
      "Train Epoch: 2 [600000/960000 (62%)]\tLoss: 0.537311\n",
      "Train Epoch: 2 [720000/960000 (75%)]\tLoss: 0.525444\n",
      "Train Epoch: 2 [840000/960000 (88%)]\tLoss: 0.514446\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 240000/240000 (100.000%)\n",
      "\n",
      "Train Epoch: 3 [0/960000 (0%)]\tLoss: 0.503375\n",
      "Train Epoch: 3 [120000/960000 (12%)]\tLoss: 0.492686\n",
      "Train Epoch: 3 [240000/960000 (25%)]\tLoss: 0.482381\n",
      "Train Epoch: 3 [360000/960000 (38%)]\tLoss: 0.472348\n",
      "Train Epoch: 3 [480000/960000 (50%)]\tLoss: 0.462816\n",
      "Train Epoch: 3 [600000/960000 (62%)]\tLoss: 0.454192\n",
      "Train Epoch: 3 [720000/960000 (75%)]\tLoss: 0.444659\n",
      "Train Epoch: 3 [840000/960000 (88%)]\tLoss: 0.434964\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 240000/240000 (100.000%)\n",
      "\n",
      "Train Epoch: 4 [0/960000 (0%)]\tLoss: 0.425871\n",
      "Train Epoch: 4 [120000/960000 (12%)]\tLoss: 0.417056\n",
      "Train Epoch: 4 [240000/960000 (25%)]\tLoss: 0.409913\n",
      "Train Epoch: 4 [360000/960000 (38%)]\tLoss: 0.401316\n",
      "Train Epoch: 4 [480000/960000 (50%)]\tLoss: 0.392694\n",
      "Train Epoch: 4 [600000/960000 (62%)]\tLoss: 0.385483\n",
      "Train Epoch: 4 [720000/960000 (75%)]\tLoss: 0.378512\n",
      "Train Epoch: 4 [840000/960000 (88%)]\tLoss: 0.372080\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 240000/240000 (100.000%)\n",
      "\n",
      "Train Epoch: 5 [0/960000 (0%)]\tLoss: 0.364548\n",
      "Train Epoch: 5 [120000/960000 (12%)]\tLoss: 0.357316\n",
      "Train Epoch: 5 [240000/960000 (25%)]\tLoss: 0.351087\n",
      "Train Epoch: 5 [360000/960000 (38%)]\tLoss: 0.344293\n",
      "Train Epoch: 5 [480000/960000 (50%)]\tLoss: 0.337861\n",
      "Train Epoch: 5 [600000/960000 (62%)]\tLoss: 0.332229\n",
      "Train Epoch: 5 [720000/960000 (75%)]\tLoss: 0.325457\n",
      "Train Epoch: 5 [840000/960000 (88%)]\tLoss: 0.319982\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 240000/240000 (100.000%)\n",
      "\n",
      "Train Epoch: 6 [0/960000 (0%)]\tLoss: 0.314934\n",
      "Train Epoch: 6 [120000/960000 (12%)]\tLoss: 0.308943\n",
      "Train Epoch: 6 [240000/960000 (25%)]\tLoss: 0.303183\n",
      "Train Epoch: 6 [360000/960000 (38%)]\tLoss: 0.297695\n",
      "Train Epoch: 6 [480000/960000 (50%)]\tLoss: 0.292817\n",
      "Train Epoch: 6 [600000/960000 (62%)]\tLoss: 0.287069\n",
      "Train Epoch: 6 [720000/960000 (75%)]\tLoss: 0.281816\n",
      "Train Epoch: 6 [840000/960000 (88%)]\tLoss: 0.277630\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 240000/240000 (100.000%)\n",
      "\n",
      "Train Epoch: 7 [0/960000 (0%)]\tLoss: 0.272547\n",
      "Train Epoch: 7 [120000/960000 (12%)]\tLoss: 0.269067\n",
      "Train Epoch: 7 [240000/960000 (25%)]\tLoss: 0.264793\n",
      "Train Epoch: 7 [360000/960000 (38%)]\tLoss: 0.259227\n",
      "Train Epoch: 7 [480000/960000 (50%)]\tLoss: 0.255129\n",
      "Train Epoch: 7 [600000/960000 (62%)]\tLoss: 0.251589\n",
      "Train Epoch: 7 [720000/960000 (75%)]\tLoss: 0.247543\n",
      "Train Epoch: 7 [840000/960000 (88%)]\tLoss: 0.242204\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 240000/240000 (100.000%)\n",
      "\n",
      "Train Epoch: 8 [0/960000 (0%)]\tLoss: 0.241039\n",
      "Train Epoch: 8 [120000/960000 (12%)]\tLoss: 0.235587\n",
      "Train Epoch: 8 [240000/960000 (25%)]\tLoss: 0.232175\n",
      "Train Epoch: 8 [360000/960000 (38%)]\tLoss: 0.228692\n",
      "Train Epoch: 8 [480000/960000 (50%)]\tLoss: 0.224599\n",
      "Train Epoch: 8 [600000/960000 (62%)]\tLoss: 0.221366\n",
      "Train Epoch: 8 [720000/960000 (75%)]\tLoss: 0.218259\n",
      "Train Epoch: 8 [840000/960000 (88%)]\tLoss: 0.214322\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 240000/240000 (100.000%)\n",
      "\n",
      "Train Epoch: 9 [0/960000 (0%)]\tLoss: 0.212275\n",
      "Train Epoch: 9 [120000/960000 (12%)]\tLoss: 0.207643\n",
      "Train Epoch: 9 [240000/960000 (25%)]\tLoss: 0.205769\n",
      "Train Epoch: 9 [360000/960000 (38%)]\tLoss: 0.201825\n",
      "Train Epoch: 9 [480000/960000 (50%)]\tLoss: 0.198688\n",
      "Train Epoch: 9 [600000/960000 (62%)]\tLoss: 0.196196\n",
      "Train Epoch: 9 [720000/960000 (75%)]\tLoss: 0.194181\n",
      "Train Epoch: 9 [840000/960000 (88%)]\tLoss: 0.190587\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 240000/240000 (100.000%)\n",
      "\n",
      "Train Epoch: 10 [0/960000 (0%)]\tLoss: 0.187678\n",
      "Train Epoch: 10 [120000/960000 (12%)]\tLoss: 0.185443\n",
      "Train Epoch: 10 [240000/960000 (25%)]\tLoss: 0.182681\n",
      "Train Epoch: 10 [360000/960000 (38%)]\tLoss: 0.179695\n",
      "Train Epoch: 10 [480000/960000 (50%)]\tLoss: 0.178008\n",
      "Train Epoch: 10 [600000/960000 (62%)]\tLoss: 0.174552\n",
      "Train Epoch: 10 [720000/960000 (75%)]\tLoss: 0.172193\n",
      "Train Epoch: 10 [840000/960000 (88%)]\tLoss: 0.170060\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 240000/240000 (100.000%)\n",
      "\n",
      "\n",
      " training DNN with 50 neurons and SGD with l2 regularizer = 0.001000\n",
      "Train Epoch: 1 [0/960000 (0%)]\tLoss: 0.676755\n",
      "Train Epoch: 1 [120000/960000 (12%)]\tLoss: 0.663736\n",
      "Train Epoch: 1 [240000/960000 (25%)]\tLoss: 0.650474\n",
      "Train Epoch: 1 [360000/960000 (38%)]\tLoss: 0.638699\n",
      "Train Epoch: 1 [480000/960000 (50%)]\tLoss: 0.625364\n",
      "Train Epoch: 1 [600000/960000 (62%)]\tLoss: 0.613810\n",
      "Train Epoch: 1 [720000/960000 (75%)]\tLoss: 0.602627\n",
      "Train Epoch: 1 [840000/960000 (88%)]\tLoss: 0.591658\n",
      "\n",
      "Test set: Average loss: 0.0006, Accuracy: 240000/240000 (100.000%)\n",
      "\n",
      "Train Epoch: 2 [0/960000 (0%)]\tLoss: 0.580723\n",
      "Train Epoch: 2 [120000/960000 (12%)]\tLoss: 0.569756\n",
      "Train Epoch: 2 [240000/960000 (25%)]\tLoss: 0.559166\n",
      "Train Epoch: 2 [360000/960000 (38%)]\tLoss: 0.549646\n",
      "Train Epoch: 2 [480000/960000 (50%)]\tLoss: 0.539287\n",
      "Train Epoch: 2 [600000/960000 (62%)]\tLoss: 0.529818\n",
      "Train Epoch: 2 [720000/960000 (75%)]\tLoss: 0.519822\n",
      "Train Epoch: 2 [840000/960000 (88%)]\tLoss: 0.510703\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 240000/240000 (100.000%)\n",
      "\n",
      "Train Epoch: 3 [0/960000 (0%)]\tLoss: 0.501532\n",
      "Train Epoch: 3 [120000/960000 (12%)]\tLoss: 0.493274\n"
     ]
    }
   ],
   "source": [
    "start_t=time.time()\n",
    "grid_search(args)\n",
    "end_t=time.time()\n",
    "\n",
    "print(end_t-start_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04940258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810e9b45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fed1e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
